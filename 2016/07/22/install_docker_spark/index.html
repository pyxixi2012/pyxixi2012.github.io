<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Install spark 1.6.0 with docker</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#00796b">
  <meta name="msapplication-TileColor" content="#4E8071"/>
  
  
  <link rel="alternative" href="/atom.xml" title="pyxixi2012 &#39;s blog" type="application/atom+xml">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css"> 
</head>


<body>

  <div id="container" class="container">
    <div class="left-col">
    <div class="intrude-less">
  <header id="header" class="inner">
    <a href="/" class="profilepic">
      <img lazy-src="/img/logo.png" class="block-select js-avatar">
	</a>
	<p class="header-subtitle">pyxixi2012</p>
    <nav class="header-menu">
      <ul>
        <li><a href="/archives">文章</a></li><li><a href="/categories/post">分类</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li>
      </ul>
    </nav>
  </header>				
</div>


    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  <div class="intrude-less">
    <header id="header" class="inner">
      <a href="/" class="profilepic">
        <img lazy-src="/img/logo.png" class="block-select js-avatar">
	  </a>
	  <p class="header-subtitle">pyxixi2012</p>
	  <nav class="header-menu">
	    <ul>
        <li><a href="/archives">文章</a></li><li><a href="/categories/post">分类</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li><div class="clearfix"></div>
		</ul>
	  </nav>
	</header>				
  </div>
</nav>

      <div class="body-wrap">
<article id="post-install_docker_spark" class="article article-type-post" itemscope itemprop="blogPost">

   
    
    <div class="article-meta">
      
<div class="article-date">
<span class="datetime-published-tag"> 2016-07-22 </span>
</div>


    </div>
    
    
  
  <div class="article-inner block-select">
  
    
    
      <header class="article-header">
        
           
  
    <h1 class="article-title" itemprop="name">
      Install spark 1.6.0 with docker
    </h1>
  

        
      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud block-select">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/docker/">docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/git/">git</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>
	</div>


        
             <div class="clearfix"></div>
        
      </div>
      
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Install-docker-on-cent-os-7-with-the-script"><a href="#Install-docker-on-cent-os-7-with-the-script" class="headerlink" title="Install docker on cent os 7 with the script"></a>Install docker on cent os 7 with the script</h2><ol>
<li><p>sudo yum update</p>
</li>
<li><p>sudo curl -fsSL <a href="https://get.docker.com/" target="_blank" rel="external">https://get.docker.com/</a> | sh</p>
</li>
<li><p>sudo service docker start</p>
</li>
<li><p>sudo usermod -aG docker yunwei</p>
</li>
<li><p>sudo docker run hello-world</p>
</li>
<li><p>sudo chkconfig docker on</p>
</li>
<li><p>close SELinux</p>
</li>
</ol>
<h2 id="Uninstall"><a href="#Uninstall" class="headerlink" title="Uninstall"></a>Uninstall</h2><ol>
<li><p>sudo yum list installed | grep docker</p>
</li>
<li><p>sudo yum -y remove docker-engine.x86_64</p>
</li>
<li><p>sudo rm -rf /var/lib/docker</p>
</li>
</ol>
<h2 id="Export-docker-images-from-existing-images"><a href="#Export-docker-images-from-existing-images" class="headerlink" title="Export docker images from existing images"></a>Export docker images from existing images</h2><ol>
<li><p>sudo docker save -o sequenceiq.hadoop-docker.tar 679730efaea5</p>
</li>
<li><p>sudo docker save -o sequenceiq.spark.tar 4f0d42f5530a</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[zgg@iZ25ff0xryjZ docker_export_tar]$ ll</div><div class="line">total 4627324</div><div class="line">-rw-r--r-- 1 root root 1805244928 Mar 29 09:47 sequenceiq.hadoop-docker.tar</div><div class="line">-rw-r--r-- 1 root root 2933123072 Mar 29 09:41 sequenceiq.spark.tar</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Import-docker-iamges-from-exported-tar-file"><a href="#Import-docker-iamges-from-exported-tar-file" class="headerlink" title="Import docker iamges from exported tar file"></a>Import docker iamges from exported tar file</h2><ol>
<li>sudo docker </li>
<li><p>–input sequenceiq.hadoop-docker.tar</p>
</li>
<li><p>sudo docker tag 789fa0a3b911 sequenceiq/hadoop-docker:2.7.0</p>
</li>
<li><p>sudo docker load –input sequenceiq.spark.tar</p>
</li>
<li><p>sudo docker tag 40a687b3cdcc sequenceiq/spark:1.6.0</p>
</li>
<li><p>sudo docker kill $(sudo docker ps -q) ; sudo docker rm $(sudo docker ps -a -q)</p>
</li>
</ol>
<h2 id="Run-hadoop-docker-and-test"><a href="#Run-hadoop-docker-and-test" class="headerlink" title="Run hadoop-docker and test"></a>Run hadoop-docker and test</h2><ol>
<li><p>git clone <a href="https://github.com/sequenceiq/hadoop-docker.git" target="_blank" rel="external">https://github.com/sequenceiq/hadoop-docker.git</a></p>
</li>
<li><p>sudo cp bootstrap.sh /etc/.</p>
</li>
<li><p>sudo docker run -it sequenceiq/hadoop-docker:2.7.0 /etc/bootstrap.sh -bash</p>
</li>
<li><p>test ,run examples</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">cd $HADOOP_PREFIX</div><div class="line"># run the mapreduce</div><div class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output &apos;dfs[a-z.]+&apos;</div><div class="line"></div><div class="line"># check the output</div><div class="line">bin/hdfs dfs -cat output/*</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Run-spark-docker-and-test"><a href="#Run-spark-docker-and-test" class="headerlink" title="Run spark-docker and test"></a>Run spark-docker and test</h2><ol>
<li><p>git clone <a href="https://github.com/sequenceiq/hadoop-docker.git" target="_blank" rel="external">https://github.com/sequenceiq/hadoop-docker.git</a></p>
</li>
<li><p>sudo docker run -it -p 8088:8088 -p 8042:8042 -p 4040:4040 -h sandbox sequenceiq/spark:1.6.0 bash<br>or docker run -d -h sandbox sequenceiq/spark:1.6.0 -d</p>
</li>
<li><p>test ,run examples</p>
<p>$ ./pyspark</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">copy readme.md to hdfs /user/root</div><div class="line"></div><div class="line">$ hadoop fs -put ./README.md /user/root/data/README.md</div><div class="line">$ hadoop fs -ls /usr/root/data</div><div class="line"></div><div class="line">$ ./pyspark</div><div class="line">&gt;&gt;&gt; file = sc.textFile(&quot;hdfs:///user/root/README.md&quot;)</div><div class="line">95</div><div class="line"></div><div class="line">$ spark-shell \</div><div class="line">  --master yarn-client \</div><div class="line">  --driver-memory 1g \</div><div class="line">  --executor-memory 1g \</div><div class="line">  --executor-cores 1</div><div class="line"></div><div class="line">scala&gt; val file = sc.textFile(&quot;hdfs:///user/root/data/README.md&quot;)</div><div class="line">res1: Long = 95</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">  YARN-client mode</div><div class="line"></div><div class="line"># run the spark shell</div><div class="line">spark-shell \</div><div class="line">--master yarn-client \</div><div class="line">--driver-memory 1g \</div><div class="line">--executor-memory 1g \</div><div class="line">--executor-cores 1</div><div class="line"></div><div class="line"># execute the the following command which should return 1000</div><div class="line">scala&gt; sc.parallelize(1 to 1000).count()</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">YARN-cluster mode</div><div class="line"></div><div class="line">In yarn-cluster mode, the Spark driver runs inside an application master process which is managed by YARN on the cluster, and the client can go away after initiating the application.</div><div class="line"></div><div class="line">Estimating Pi (yarn-cluster mode):</div><div class="line"></div><div class="line"># execute the the following command which should write the &quot;Pi is roughly 3.1418&quot; into the logs</div><div class="line"># note you must specify --files argument in cluster mode to enable metrics</div><div class="line">spark-submit \</div><div class="line">--class org.apache.spark.examples.SparkPi \</div><div class="line">--files $SPARK_HOME/conf/metrics.properties \</div><div class="line">--master yarn-cluster \</div><div class="line">--driver-memory 1g \</div><div class="line">--executor-memory 1g \</div><div class="line">--executor-cores 1 \</div><div class="line">$SPARK_HOME/lib/spark-examples-1.6.0-hadoop2.6.0.jar</div><div class="line">Estimating Pi (yarn-client mode):</div><div class="line"></div><div class="line"># execute the the following command which should print the &quot;Pi is roughly 3.1418&quot; to the screen</div><div class="line">spark-submit \</div><div class="line">--class org.apache.spark.examples.SparkPi \</div><div class="line">--master yarn-client \</div><div class="line">--driver-memory 1g \</div><div class="line">--executor-memory 1g \</div><div class="line">--executor-cores 1 \</div><div class="line">$SPARK_HOME/lib/spark-examples-1.6.0-hadoop2.6.0.jar</div></pre></td></tr></table></figure>

      
      
      
        <div class="post-copyright">
<p><a href="http://pyxixi2012.github.io/2016/07/22/install_docker_spark/">本文</a>为原创，转载请遵守本站<a href="/copyright/">版权声明</a></p>
<p class="updated-time" >更新于: </span>2016年7月23日 10:07</p>
</div>

      
    </div>
    
  </div>
  
    
<nav id="article-nav" class="block-select">
  
    <a href="/2016/07/23/学习Hexo，搭建一个git-pages的博客/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          学习Hexo，搭建一个git pages的博客
        
      </div>
    </a>
  
  
    <a href="/2016/07/22/kafka-docker-usage/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">kafka with docker 常用命令</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>


  
</article>




<section id="comments">
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'pyxixi2012'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>


</div>
      <footer id="footer" class="block-select">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">&copy; 2015-2016
        <a href="/about" class ="aboutme-foot-tag"> alex yang</a>
      </div>
    </div>
  </div>
</footer>

    </div>
    <script>
	var ThemeXConfig = {fancybox: false,mathjax: false,animate: true,isHome: false,isPost: true,isArchive: false,isTag: false,isCategory: false,open_in_new: false, CDN_PATH: '' }
</script>


    <script src="/js/jquery-1.9.1.min.js"></script>
    <script src="/js/base.js"></script>
    <script src="/js/jquery.lazyload.min.js"></script>





  </div>
</body>
</html>
